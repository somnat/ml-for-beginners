{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "\n",
    "        def __init__(self, train_x, train_y, hidden_neurons=1, bias = 0):\n",
    "            self.train_x = train_x\n",
    "            self.train_y = train_y\n",
    "            \n",
    "            self.hidden_neurons = hidden_neurons\n",
    "            self.input_nodes = np.shape(train_x)[0]\n",
    "            self.output_nodes = np.shape(train_y)[0]\n",
    "            self.bias = bias\n",
    "\n",
    "            # seed for the fixed random values\n",
    "            np.random.seed(3)\n",
    "            self.W_in = np.random.normal(0.0, 0.1, (self.input_nodes, self.hidden_neurons))\n",
    "             \n",
    "                    \n",
    "        def L2_loss(self, Y_pred, Y_train):\n",
    "            return np.sum(np.power((Y_pred - Y_train), 2)) / len(Y_train)\n",
    "        \n",
    "        def sigmoid(self, x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        \n",
    "        def derivative_L2_loss(x):\n",
    "            return -x\n",
    "\n",
    "        def derivative_L1_loss(x):\n",
    "            return -1\n",
    "\n",
    "        def forward_prop(self):\n",
    "            # Layewise activation output\n",
    "            print(self.input_nodes)\n",
    "            print(self.output_nodes)\n",
    "            self.lw_net = list()\n",
    "            self.lw_act_out = list()\n",
    "            self.X_i = np.dot(self.train_x.T, self.W_in) + self.bias\n",
    "            self.A_i = self.sigmoid(self.X_i)\n",
    "            self.E = self.L2_loss(np.array(self.A_i), np.array(self.train_y))\n",
    "                        \n",
    "#       backpropagation\n",
    "        def back_prop(self):\n",
    "            self.loss = self.E\n",
    "            self.dloss = - (self.train_y - self.A_i)*self.A_i*(1-self.A_i)*self.train_x\n",
    "        \n",
    "#       optimization\n",
    "        def optimization(self, lr= 0.001):\n",
    "            self.W_in = self.W_in + lr * self.dloss\n",
    "        \n",
    "#       train the network\n",
    "\n",
    "        def train(self, n_iterations = 10):\n",
    "            for i in range(n_iterations):\n",
    "                # forward pass\n",
    "                self.forward_prop()\n",
    "                self.back_prop()\n",
    "                self.optimization()\n",
    "            print(self.W_in)\n",
    "            print(self.W_in*train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[[0.1782794]]\n",
      "[[0.0891397]]\n"
     ]
    }
   ],
   "source": [
    "train_x = np.array([0.5])\n",
    "train_y = np.array([0.99])\n",
    "nn = Perceptron(train_x, train_y)\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
